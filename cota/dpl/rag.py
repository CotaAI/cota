import os
import logging
from pathlib import Path
from typing import Text, List, Dict, Optional, Union, Tuple, Any
from cota.dst import DST
from cota.actions.action import Action
from cota.dpl.dpl import DPL
from cota.utils.io import read_yaml_from_path
from cota.utils.common import hash_str
from cota.constant import DEFAULT_DIALOGUE_MAX_TOKENS

logger = logging.getLogger(__name__)


class RAGDPL(DPL):
    """RAG-based Dialogue Policy Learning class that uses LLM to retrieve thoughts."""
    
    def __init__(
        self,
        path: Union[Text, Path],
        llm: Union[Text, Dict, List, None] = None,
        max_thoughts: int = 5
    ) -> None:
        """Initialize RAGDPL with policy data."""
        self.llm = llm
        self.max_thoughts = max_thoughts
        self.knowledge_files = {}  # Dictionary to store knowledge files for each action type
        self.build(path)
    
    def get_llm_for_action(self, action_name: str) -> Optional[str]:
        """Get LLM configuration for specific action type.
        """
        if not self.llm:
            return None
            
        # Handle string format (single LLM for all actions)
        if isinstance(self.llm, str):
            return self.llm
            
        # Handle dictionary format (action-specific LLMs)
        elif isinstance(self.llm, dict):
            # First try exact match
            if action_name in self.llm:
                return self.llm[action_name]
            # Fallback to 'default' key if available
            return self.llm.get('default')
            
        else:
            logger.warning(f"Unsupported LLM config type: {type(self.llm)}")
            return None
    
    def build(self, path: Union[Text, Path]):
        """Prepare data for RAG with streaming processing."""
        # Load policy data from path
        policies = self.load_data(path)

        if not policies:
            logger.warning(f"No policies found in {path}")
            return {}

        # Stream process: read policies and write to file directly
        self.process_policies(policies, path)

        # Log reminder for RAG platform submission
        logger.info("=" * 60)
        logger.info("ðŸ“‹ RAG DPL Data Preparation Complete (Auto-Generated by Action Type)")
        logger.info("=" * 60)
        logger.info(f"ðŸ“ Source path: {path}")
        logger.info(f"ðŸ¤– Auto-detected {len(self.knowledge_files)} action types with thoughts")
        logger.info("")
        logger.info("âš ï¸  IMPORTANT: Please submit the following data to your RAG platform:")
        logger.info(f"   1. Upload all {len(self.knowledge_files)} generated knowledge files to your knowledge base")
        logger.info("   2. Configure RAG retrieval endpoints for each action type")
        logger.info("   3. Test RAG query functionality for all action types")
        logger.info("ðŸ“¤ Ready-to-upload files automatically separated by action type")
        logger.info("=" * 60)

    def process_policies(self, policies: List[Dict], policies_path: Union[Text, Path]):
        """Process policies: read and write to file directly for all action types."""
        import time
        
        policies_path = Path(policies_path)
        timestamp = int(time.time())
        
        # First pass: collect all action types that have thoughts
        action_types = set()
        for policy in policies:
            actions = policy.get("actions", [])
            for action in actions:
                if 'thought' in action:
                    action_name = action.get('name', '')
                    if action_name:
                        action_types.add(action_name)
        
        if not action_types:
            logger.warning("No actions with thoughts found in policies")
            return
        
        # Create output files for each action type
        action_files = {}
        action_hash_keys = {}
        file_handles = {}
        
        try:
            # Initialize files and data structures for each action type
            for action_type in action_types:
                safe_action_name = action_type.lower().replace(' ', '_')
                output_path = policies_path / f"rag_dpl_{safe_action_name}_{timestamp}.md"
                output_path.parent.mkdir(parents=True, exist_ok=True)
                
                # Store file path for later retrieval
                self.knowledge_files[action_type] = output_path
                action_hash_keys[action_type] = set()
                file_handles[action_type] = open(output_path, 'w', encoding='utf-8')
                
                logger.info(f"Created knowledge file for {action_type}: {output_path.name}")
            
            # Process all policies
            for policy_idx, policy in enumerate(policies):
                actions = policy.get("actions", [])
                if not actions:
                    continue
                
                policy_title = policy.get("title", f"policy_{policy_idx}")
                user_utter_index = self.build_user_utter_index(actions)
                
                for i, action in enumerate(actions):
                    if 'thought' in action:
                        action_name = action.get('name', '')
                        
                        # Skip if action type not found or no file handle
                        if action_name not in file_handles:
                            continue
                        
                        target_file = file_handles[action_name]
                        target_hash_keys = action_hash_keys[action_name]
                        
                        segments = self.trace_back_to_user_utter(actions, i, user_utter_index)
                        
                        for segment in segments:
                            hash_key = '_'.join(f"{action.get('name')}:{action.get('thought', '')}" for action in segment)
                            if hash_str(hash_key) not in target_hash_keys:
                                target_hash_keys.add(hash_str(hash_key))
                                
                                content = self.segment_to_rag_content(segment)
                                if content:
                                    target_file.write(f"# {policy_title}\n")
                                    target_file.write(f"{content}\n")
                                    target_file.write(f"\n\n")
        
        finally:
            # Close all file handles
            for file_handle in file_handles.values():
                file_handle.close()
            
        logger.info(f"Generated knowledge files for {len(action_types)} action types: {list(action_types)}")


    def segment_to_rag_content(self, segment: List[Dict]) -> str:
        """Convert action segment to RAG document content."""
        content_lines = []
        
        for action in segment:
            action_name = action.get('name')
            if not action_name:
                continue
            
            # Add thought if available
            if action.get('thought'):
                content_lines.append(f"thought:{action.get('thought')}")

            # Add action result if available
            if action.get('result'):
                content_lines.append(f"{action_name}:{action.get('result')}")
        
        return "\n".join(content_lines)
    
    async def generate_thoughts(self, dst: DST, action: Action) -> Text:
        """Generate thoughts using LLM with action-specific configuration."""
        # Determine action name
        action_name = action.name if hasattr(action, 'name') else action.__class__.__name__
        
        # Get LLM for this action type
        llm_name = self.get_llm_for_action(action_name)
        if not llm_name:
            logger.warning(f"No LLM configured for action type: {action_name}")
            return ""
        
        # Build query from current context
        query_text = self.build_rag_query(dst, action)
        if not query_text.strip():
            logger.debug("Empty query text for RAG retrieval")
            return ""
        
        logger.debug(f"Using LLM '{llm_name}' for action '{action_name}'")
        
        try:
            result = await dst.agent.llm_instance(llm_name).generate_chat(
                messages=[
                    {
                        "role":"user", 
                        "content": query_text
                    }
                ],
                max_tokens=dst.agent.dialogue.get('max_tokens', DEFAULT_DIALOGUE_MAX_TOKENS)
            )
            return result["content"]
        except Exception as e:
            logger.error(f"Failed to generate thoughts for {action_name} using {llm_name}: {e}")
            return ""

    def build_rag_query(self, dst: DST, action: Action) -> Text:
        """Build query text for RAG platform using the longest context segment."""
        actions = dst.formless_actions
        segment_parts = []
        for act in actions:
            if act and act.result.get('text'):
                segment_parts.append(f"{act.name}:{act.result.get('text','')}")
        
        # Return the complete segment as query
        return "\n".join(segment_parts)
        
    def load_data(self, path: Union[Text, Path]) -> List[Dict]:
        """Load policy data from YAML files, similar to MatchDPL."""
        policies = []
        path_obj = Path(path)

        if not path_obj.is_dir():
            logger.warning(f"Path {path} is not a directory")
            return policies

        # Process all YAML files in directory
        for yml_file in path_obj.glob('*.yml'):
            try:
                data = read_yaml_from_path(yml_file)
                
                # Only extract data from 'policies' sections
                if isinstance(data, dict) and 'policies' in data:
                    policies.extend(data['policies'])
            except Exception as e:
                logger.error(f"Failed to load {yml_file}: {e}")
                
        return policies

    def build_user_utter_index(self, actions):
        return [i for i, action in enumerate(actions) if action.get('name') == 'UserUtter']

    def trace_back_to_user_utter(self, actions, index, user_utter_index):
        segments = []
        for q_index in reversed(user_utter_index):
            if q_index < index:
                segment = [action for action in actions[q_index:index] if action.get('name') and action.get('name') not in ('Selector','Updater')]
                segment.append(actions[index])
                if len(segment) > 1:
                    segments.append(segment)
        return segments
